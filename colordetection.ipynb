{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e2297e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "\n",
    "import cv2\n",
    "from random import randint\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28737fa",
   "metadata": {},
   "source": [
    "## Check Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb5b647",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES, gems = [], [] \n",
    "for root, dirs, files in os.walk('C:/Users/User/Desktop/Research Project/images'):\n",
    "    f = os.path.basename(root)      \n",
    "        \n",
    "    if len(files) > 0:\n",
    "        gems.append(len(files))\n",
    "        if f not in CLASSES:\n",
    "            CLASSES.append(f) \n",
    "    \n",
    "    [] else 0)) \n",
    "    \n",
    "gems_count = len(CLASSES) \n",
    "print('{} classes with {} images in total'.format(len(CLASSES), sum(gems)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ece210",
   "metadata": {},
   "source": [
    "## Prepare Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d798e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_w, img_h = 220, 220    \n",
    "train_dir = 'C:/Users/User/Desktop/Research Project/images/train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d369ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_imgs_lbls(_dir):\n",
    "    Images, Labels = [], []\n",
    "    for root, dirs, files in os.walk(_dir):\n",
    "        f = os.path.basename(root)     \n",
    "        for file in files:\n",
    "            Labels.append(f)\n",
    "            try:\n",
    "                image = cv2.imread(root+'/'+file)              \n",
    "                image = cv2.resize(image,(int(img_w*1.5), int(img_h*1.5)))       \n",
    "                image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV) \n",
    "                Images.append(image)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "    Images = np.array(Images)\n",
    "    return (Images, Labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8440c322",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_index(Labels):\n",
    "    for i, n in enumerate(Labels):\n",
    "        for j, k in enumerate(CLASSES):    \n",
    "            if n == k:\n",
    "                Labels[i] = j\n",
    "    Labels = np.array(Labels)\n",
    "    return Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057bdb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_Imgs, Train_Lbls = read_imgs_lbls(train_dir)\n",
    "Train_Lbls = get_class_index(Train_Lbls)\n",
    "print('Shape of train images: {}'.format(Train_Imgs.shape))\n",
    "print('Shape of train labels: {}'.format(Train_Lbls.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67afd718",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 5 #5x5 dimension flat plot\n",
    "\n",
    "f,ax = plt.subplots(dim,dim) \n",
    "f.subplots_adjust(0,0,2,2)\n",
    "for i in range(0,dim):\n",
    "    for j in range(0,dim):\n",
    "        rnd_number = randint(0,len(Train_Imgs))\n",
    "        cl = Train_Lbls[rnd_number]\n",
    "        ax[i,j].imshow(Train_Imgs[rnd_number])\n",
    "        ax[i,j].set_title(CLASSES[cl]+': ' + str(cl))\n",
    "        ax[i,j].axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e527bc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def edge_and_cut(img):\n",
    "    try:\n",
    "        edges = cv2.Canny(img, img_w, img_h)            \n",
    "        \n",
    "        if(np.count_nonzero(edges)>edges.size/10000):           \n",
    "            pts = np.argwhere(edges>0)\n",
    "            y1,x1 = pts.min(axis=0)\n",
    "            y2,x2 = pts.max(axis=0)\n",
    "            \n",
    "            new_img = img[y1:y2, x1:x2]           # crop the region\n",
    "            new_img = cv2.resize(new_img,(img_w, img_h))  # Convert back\n",
    "        else:\n",
    "            new_img = cv2.resize(img,(img_w, img_h))\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        new_img = cv2.resize(img,(img_w, img_h))\n",
    "    \n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c6d3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_cropped(img):\n",
    "    emb_img = img.copy()\n",
    "    edges = cv2.Canny(img, img_w, img_h)\n",
    "    \n",
    "    if(np.count_nonzero(edges)>edges.size/10000):\n",
    "        pts = np.argwhere(edges>0)\n",
    "        y1,x1 = pts.min(axis=0)\n",
    "        y2,x2 = pts.max(axis=0)\n",
    "\n",
    "        new_img = img[y1:y2, x1:x2]  \n",
    "\n",
    "        edge_size = 1 #replace it with bigger size for larger images            \n",
    "\n",
    "        emb_img[y1-edge_size:y1+edge_size, x1:x2] = [255, 0, 0]\n",
    "        emb_img[y2-edge_size:y2+edge_size, x1:x2] = [255, 0, 0]\n",
    "        emb_img[y1:y2, x1-edge_size:x1+edge_size] = [255, 0, 0]\n",
    "        emb_img[y1:y2, x2-edge_size:x2+edge_size] = [255, 0, 0]\n",
    "\n",
    "        new_img = cv2.resize(new_img,(img_w, img_h))  # Convert to primary size  \n",
    "        \n",
    "    else:\n",
    "        new_img = cv2.resize(img,(img_w, img_h))\n",
    "    \n",
    "    fig, ax = plt.subplots(nrows=1, ncols=4, figsize=(10, 10))\n",
    "    ax[0].imshow(img, cmap='gray')\n",
    "    ax[0].set_title('Original Image', fontsize=14)\n",
    "    ax[1].imshow(edges, cmap='gray')\n",
    "    ax[1].set_title('Canny Edges', fontsize=14)\n",
    "    ax[2].imshow(emb_img, cmap='gray')\n",
    "    ax[2].set_title('Bounding Box', fontsize=14)       \n",
    "    ax[3].imshow(new_img, cmap='gray')\n",
    "    ax[3].set_title('Cropped', fontsize=14)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7a5194",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(0,3):\n",
    "    show_cropped(Train_Imgs[randint(0,len(Train_Imgs))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf389b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_images(Imgs):\n",
    "    CroppedImages = np.ndarray(shape=(len(Imgs), img_w, img_h, 3), dtype=np.int)\n",
    "\n",
    "    ind = 0\n",
    "    for im in Imgs: \n",
    "        x = edge_and_cut(im)\n",
    "        CroppedImages[ind] = x\n",
    "        ind += 1\n",
    "\n",
    "    return CroppedImages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b246ddf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_Imgs = crop_images(Train_Imgs)\n",
    "print('Final shape of images in train set: {} '.format(Train_Imgs.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccad9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(Train_Imgs, Train_Lbls, shuffle = True, test_size = 0.2, random_state = 42)\n",
    "print('Shape of X_train: {}, y_train: {} '.format(X_train.shape, y_train.shape))\n",
    "print('Shape of X_val: {}, y_val: {} '.format(X_val.shape, y_val.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccdca6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53abab90",
   "metadata": {},
   "source": [
    "# Build a CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c69807",
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = 32      \n",
    "kernel_size = 3   \n",
    "max_pool = 2      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0380c532",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 70                                  \n",
    "batch_size = 32                               \n",
    "iter_per_epoch = len(X_train) // batch_size  \n",
    "val_per_epoch = len(X_val) // batch_size     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ce6f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# first layer\n",
    "model.add(Conv2D(batch_size, (kernel_size, kernel_size), activation='relu', padding='same', input_shape=(img_w, img_h, 3))) # 32\n",
    "model.add(MaxPooling2D((max_pool, max_pool))) \n",
    "\n",
    "# second layer\n",
    "model.add(Conv2D(2*batch_size, (kernel_size, kernel_size), activation='relu', padding='same')) # 64\n",
    "model.add(MaxPooling2D((max_pool, max_pool))) \n",
    "\n",
    "# third layer\n",
    "model.add(Conv2D(4*batch_size, (kernel_size, kernel_size), activation='relu', padding='same')) # 128\n",
    "model.add(MaxPooling2D((max_pool, max_pool))) \n",
    "\n",
    "# fourth layer\n",
    "model.add(Conv2D(4*batch_size, (kernel_size, kernel_size), activation='relu', padding='same')) # 128\n",
    "model.add(AveragePooling2D(pool_size= (2, 2), strides= (2, 2))) \n",
    "\n",
    "# fifth layer\n",
    "model.add(Conv2D(4*batch_size, (kernel_size, kernel_size), activation='relu', padding='same')) # 128\n",
    "model.add(MaxPooling2D((max_pool, max_pool))) \n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(16*batch_size, activation='relu'))                                             # 512\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbe1ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69231bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(              \n",
    "        rotation_range=25,\n",
    "        zoom_range=0.1,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0.2,\n",
    "        horizontal_flip=True\n",
    "        )\n",
    "\n",
    "val_datagen = ImageDataGenerator()                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044cb8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = randint(0,len(X_train))\n",
    "samples = np.expand_dims(X_train[n], 0)\n",
    "it = train_datagen.flow(samples, batch_size=batch_size)\n",
    "cols = 7\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=cols, figsize=(15, 10))\n",
    "ax[0].imshow(X_train[n], cmap='gray')\n",
    "ax[0].set_title('Original', fontsize=10)\n",
    "\n",
    "for i in range(1,cols):\n",
    "    batch = it.next()   \n",
    "    image = batch[0].astype('uint32') \n",
    "    ax[i].set_title('augmented {}'.format(i), fontsize=10)\n",
    "    ax[i].imshow(image, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98ac186",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = train_datagen.flow(X_train, y_train, batch_size=batch_size)\n",
    "val_gen = val_datagen.flow(X_val, y_val, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac6af61",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = model.fit_generator(\n",
    "       train_gen,\n",
    "       steps_per_epoch= iter_per_epoch,\n",
    "       epochs=EPOCHS, \n",
    "       validation_data = val_gen,\n",
    "       validation_steps = val_per_epoch,\n",
    "       verbose = 1 # Verbosity mode. 0 = silent, 1 = progress bar, 2 = one line per epoch.\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd9fb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate_generator(val_gen, steps= len(val_gen))\n",
    "\n",
    "for idx, metric in enumerate(model.metrics_names):\n",
    "    print('{}:{}'.format(metric, score[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56363f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "y_pre_test=model.predict(X_val)\n",
    "y_pre_test=np.argmax(y_pre_test,axis=1)\n",
    "cm=confusion_matrix(y_val,y_pre_test)\n",
    "\n",
    "plt.figure(figsize = (5,5))\n",
    "sn.heatmap(cm, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b9b16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=(y_pre_test-y_val!=0).tolist()\n",
    "x=[i for i,l in enumerate(x) if l!=False]\n",
    "\n",
    "fig,ax=plt.subplots(1,5,sharey=False,figsize=(13,13))\n",
    "fig.tight_layout()\n",
    "\n",
    "for i in range(5):\n",
    "    ax[i].imshow(X_val[x[i]][:,:,1])\n",
    "    ax[i].set_xlabel('{}, Pred: {}'.format(CLASSES[y_val[x[i]]],CLASSES[y_pre_test[x[i]]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a94c5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_rpcdpp1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba049d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = 'C:/Users/User/Desktop/Research Project/images/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3c55fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_Imgs, Test_Lbls = read_imgs_lbls(test_dir)\n",
    "Test_Lbls = get_class_index(Test_Lbls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38f07ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_Imgs = crop_images(Test_Imgs)\n",
    "print('shape of images in test set: {} '.format(Test_Imgs.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91dbbb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax = plt.subplots(5,5) \n",
    "f.subplots_adjust(0,0,2,2)\n",
    "for i in range(0,5,1):\n",
    "    for j in range(0,5,1):\n",
    "        rnd_number = randint(0,len(Test_Imgs))\n",
    "        pred_image = np.array([Test_Imgs[rnd_number]])\n",
    "        pred_class = model.predict_classes(pred_image)[0]\n",
    "        pred_prob = model.predict(pred_image).reshape(5)\n",
    "        act = CLASSES[Test_Lbls[rnd_number]]\n",
    "        ax[i,j].imshow(Test_Imgs[rnd_number])\n",
    "        ax[i,j].imshow(pred_image[0])\n",
    "        if(CLASSES[pred_class] != CLASSES[Test_Lbls[rnd_number]]):\n",
    "            t = '{} [{}]'.format(CLASSES[pred_class], CLASSES[Test_Lbls[rnd_number]])\n",
    "            ax[i,j].set_title(t, fontdict={'color': 'darkred'})\n",
    "        else:\n",
    "            t = '[OK] {}'.format(CLASSES[pred_class]) \n",
    "            ax[i,j].set_title(t)\n",
    "        ax[i,j].axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e8df0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb4e37d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
